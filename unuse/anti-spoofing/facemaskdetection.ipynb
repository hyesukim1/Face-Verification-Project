{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "facemaskdetection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO1boRdsvQ81KjIBJ+IpqHd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyesukim1/Face-Verification-Project/blob/main/facemaskdetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH0OYTe0h7Kq"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls -1ha kaggle.json"
      ],
      "metadata": {
        "id": "kLjnMZBHj8ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Permission Warning 방지\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "R0OJZTpQkFk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d andrewmvd/face-mask-detection"
      ],
      "metadata": {
        "id": "E1AjESomkKoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "PlGz1Jy3kdFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"/content/face-mask-detection.zip\""
      ],
      "metadata": {
        "id": "ZQQSwrKNu3dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "metadata": {
        "id": "OdBwOb3duUgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets, models\n",
        "import torch\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "import matplotlib.patches as patches\n",
        "import os\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "ASlHViHUkzyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_box(obj):\n",
        "  xmin = int(obj.find('xmin').text)\n",
        "  ymin = int(obj.find('ymin').text)\n",
        "  xmax = int(obj.find('xmax').text)\n",
        "  ymax = int(obj.find('ymax').text)\n",
        "  return [xmin, ymin, xmax, ymax]\n",
        "\n",
        "def generate_label(obj):\n",
        "  if obj.find('name').text == 'with_mask':\n",
        "    return 1\n",
        "  elif obj.find('name').text == 'mask_weared_incorrect':\n",
        "    return 2\n",
        "  return 0\n",
        "\n",
        "def generate_target(image_id, file):\n",
        "  with open(file) as f:\n",
        "    data = f.read()\n",
        "    soup = BeautifulSoup(data, 'xml')\n",
        "    objects = soup.find_all('object')\n",
        "\n",
        "    num_objs = len(objects)\n",
        "\n",
        "    # bounding boxes for objects\n",
        "    boxes = []\n",
        "    labels = []\n",
        "\n",
        "    for i in objects:\n",
        "      boxes.append(generate_box(i))\n",
        "      labels.append(generate_label(i))\n",
        "    \n",
        "    # boxes, labels to tensor\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "    \n",
        "    #tensorise image id\n",
        "    img_id = torch.tensor([image_id])\n",
        "\n",
        "    target = {}\n",
        "    target['boxes'] = boxes\n",
        "    target['labels'] = labels\n",
        "    target['image_id'] = img_id\n",
        "\n",
        "    return target\n"
      ],
      "metadata": {
        "id": "TIub1M_2lGG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = list(sorted(os.listdir(\"/content/images/\")))\n",
        "labels = list(sorted(os.listdir(\"/content/annotations/\")))"
      ],
      "metadata": {
        "id": "MXH5sVwglRSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskDataset(object):\n",
        "  def __init__(self, transforms):\n",
        "    self.transforms = transforms\n",
        "    # load all images files, because of sorting them that they are aligned\n",
        "    self.imgs = list(sorted(os.listdir(\"/content/images/\")))\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    file_image = 'maksssksksss' + str(idx) + '.png'\n",
        "    file_label = 'maksssksksss' + str(idx) + '.xml'\n",
        "    img_path = os.path.join(\"/content/images/\" , file_image)\n",
        "    label_path = os.path.join(\"/content/annotations/\" , file_label)\n",
        "\n",
        "    img = Image.open(img_path).convert(\"RGB\")\n",
        "    target = generate_target(idx, label_path)\n",
        "\n",
        "    if self.transforms is not None:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    return img, target"
      ],
      "metadata": {
        "id": "rW6hpz94qtIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "2bGkEBwbsdON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  return tuple(zip(*batch))\n",
        "\n",
        "dataset = MaskDataset(data_transform)\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=4, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "1010f9CKtN_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_loader)"
      ],
      "metadata": {
        "id": "DfxayRXE2VEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "5bJWhEPZtqeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make model & train"
      ],
      "metadata": {
        "id": "aFf-0NUwvLvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_instance_segmentation(num_classes):\n",
        "  # coco dataset에서 미리 학습된 인스턴스 분할 모델 읽어오기\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  # 분류를 위한 입력 특징 차원을 얻음\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  # 미리 학습된 헤더를 새로운 것으로 바꿈\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "h5ypRXIntsf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3개 클래스로 분류하는 모델\n",
        "model = get_model_instance_segmentation(3)"
      ],
      "metadata": {
        "id": "t5801voBxNlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "W1xTo-WZxyJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imgs, annotations in data_loader:\n",
        "    imgs = list(img.to(device) for img in imgs)\n",
        "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "    print(annotations)\n",
        "    break"
      ],
      "metadata": {
        "id": "sOW-wCvcyqff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "model.to(device)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "len_detaloader = len(data_loader)\n",
        "print(len_detaloader)\n",
        "# print(params)\n",
        "# print(optimizer)"
      ],
      "metadata": {
        "id": "WNvK-FHn0Evr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  i = 0\n",
        "  epoch_loss = 0\n",
        "  for imgs, annotations in data_loader:\n",
        "    i += 1\n",
        "    imgs = list(img.to(device) for img in imgs)\n",
        "    annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "    loss_dict = model([imgs[0]], [annotations[0]])\n",
        "    losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    losses.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += losses\n",
        "\n",
        "  print(epoch_loss)"
      ],
      "metadata": {
        "id": "AuAlTBl-HWXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imgs, annotations in data_loader:\n",
        "  imgs = list(img.to(device) for img in imgs)\n",
        "  annotations = [{k: v.to(device) for k, v in t.items()} for t in annotations]\n",
        "  break"
      ],
      "metadata": {
        "id": "sMKsJd0cDGlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds = model(imgs)\n",
        "print(preds[2]['boxes'])"
      ],
      "metadata": {
        "id": "k8-FtwacFVP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# show images"
      ],
      "metadata": {
        "id": "cCS3CY0cFcgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(img_tensor, annotation):\n",
        "\n",
        "  fig,ax = plt.subplots(1)\n",
        "  img = img_tensor.cpu().data\n",
        "\n",
        "  ax.imshow(img.permute(1, 2, 0))\n",
        "\n",
        "  for box in annotation[\"boxes\"].cpu().data.numpy():\n",
        "    xmin, ymin, xmax, ymax = box\n",
        "\n",
        "    rect = patches.Rectangle((xmin, ymin), (xmax-xmin), (ymax-ymin), linewidth=1, edgecolor='r', facecolor='none')\n",
        "\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "KYfI4Jy9FaUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Prediction\")\n",
        "plot_image(imgs[2], preds[2])\n",
        "print(\"Target\")\n",
        "plot_image(imgs[2], annotations[2])"
      ],
      "metadata": {
        "id": "niNOb9Q4GTM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save model"
      ],
      "metadata": {
        "id": "PnIuALACIlGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pt')\n",
        "model2 = get_model_instance_segmentation(3)"
      ],
      "metadata": {
        "id": "g3VB7q8HG4eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.load_state_dict(torch.load('model.pt'))\n",
        "model2.eval()\n",
        "model2.to(device)"
      ],
      "metadata": {
        "id": "-JlxR7jpIjy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "bmMw1dAtI1h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict2 = model2(imgs)"
      ],
      "metadata": {
        "id": "BMdjaFW3Iynl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"prediction with loaded model\")\n",
        "plot_image(imgs[3], predict2[3])"
      ],
      "metadata": {
        "id": "dnwSdO_OI7hs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}